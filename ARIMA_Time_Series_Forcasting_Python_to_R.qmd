---
title: "ARIMA Time Series Forecasting - Python to R"

format:
  pdf:
    include-in-header:
      text: |
        \addtokomafont{disposition}{\rmfamily}
  html: default
---

# Introduction

Time series forecasting is a very attractive idea for researchers, especially in the context of forecasting financial asset prices. However, for centuries mathematicians and scholars who attempted such thing almost always have failed, leading many to believe that market returns are a white noise - a completely random time series.

# Data

```{r include=FALSE}
library(xts)
library(foreach)
library(doParallel)
library(cowplot)
library(readr)
library(ggplot2)
library(quantmod)
library(tseries)
library(forecast)
library(gridExtra)
library(Metrics)
library(stats)
```


```{r include=FALSE}
df <- read.csv("C:\\Users\\marci\\OneDrive\\Dokumenty\\Nowy folder\\RR2023_project\\sp500_data.csv")
```
# Metodology step 1
We used the ggplot2 package to visually examine the stationarity of the time series. We plotted the prices and returns of sp500 and based on our visual analysis, we concluded that the price time series is non-stationary.

```{r}
df <- na.omit(df)
df$Date <- as.Date(df$Date)

p1 <- ggplot(df, aes(x = Date)) +
  geom_line(aes(y = GSPC.Open, color = "Price"), size = 1) +
  geom_line(aes(y = GSPC.High, color = "Price"), size = 1) +
  geom_line(aes(y = GSPC.Low, color = "Price"), size = 1) +
  geom_line(aes(y = GSPC.Close, color = "Price"), size = 1) +
  labs(x = "Date", y = "Price", color = "Price") +
  scale_color_manual(values = c("Price" = "purple")) +
  theme_minimal()

p2 <- ggplot(df, aes(x = Date)) +
  geom_line(aes(y = GSPC.Volume/1e9), color = "orange", size = 1) +
  labs(y = "Volume (B)") +
  theme_minimal()


combined_plot <- plot_grid(p1, p2, nrow = 2, align = "v", axis = "l")

print(combined_plot)
```
# Metodology step 2
Now we used the ggplot2 package to visually examine the stationarity of the returns of SP500. In addition, we also conducted an Augmented Dickey-Fuller (ADF) test to confirm the aforementioned observations. The ADF test provided further evidence supporting our conclusions, indicating that the price time series is indeed non-stationary, while the returns time series is stationary.

```{r}
timeseries <- df$GSPC.Close

adf_result <- adf.test(timeseries)

cat("ADF Statistic:", adf_result$statistic, "\n")
cat("p-value:", adf_result$p.value, "\n")

#Calc of returns 

closing_prices <- df$GSPC.Close

returns <- diff(closing_prices) / lag(closing_prices)

adf_result <- adf.test(returns, alternative = "stationary")

cat("ADF Statistic:", adf_result$statistic, "\n")
cat("p-value:", adf_result$p.value, "\n")

time_index <- time(closing_prices)[-1]

# Remove missing values from time_index and returns
complete_data <- !is.na(time_index) & !is.na(returns)
time_index <- time_index[complete_data]
returns <- returns[complete_data]

plot(time_index, returns, type = "l", xlab = "Time", ylab = "Returns", main = "SP500 Daily Returns")

```
# Metodology step 3
The code below conducts a grid search to find the optimal values of p, d, and q for an ARIMA model by evaluating the AIC values for different combinations. The combination with the lowest AIC value is considered to be the best set of parameters for the model.

```{r echo=}
dfret <- data.frame(Date = as.Date(time_index), Returns = returns)

# Convert the Date column to a proper date format
dfret$Date <- as.Date(dfret$Date)

# Remove rows with NA, NaN, or Inf in the Date or Returns columns
dfret <- dfret[complete.cases(dfret$Date, dfret$Returns), ]

# Create the xts object
xts_obj <- xts(dfret$Returns, order.by = dfret$Date)

# Rename a column in an xts object
colnames(xts_obj)[1] <- "Return"

# Define the p, d, and q parameters to take any value between 0 and 2
p <- d <- q <- 0:2

# Generate all different combinations of p, d, and q triplets
pdq <- expand.grid(p = p, d = d, q = q)

# Perform a grid search to find the optimal set of parameters that yields the best performance
best_aic <- Inf
best_pdq <- c(NA, NA, NA)

for(i in 1:nrow(pdq)) {
  model <- arima(xts_obj, order = c(pdq[i, "p"], pdq[i, "d"], pdq[i, "q"]))
  if(AIC(model) < best_aic) {
    best_aic <- AIC(model)
    best_pdq <- pdq[i, ]
  }
}

best_pdq
cat(" x 12 Model - AIC:", best_aic,"\n")
```
# Metodology step 4
Code below splits the data into train and test sets, fits an ARIMA model to the training data, makes predictions on the test data using the model, and plots the actual values along with the predicted values for visualization and comparison.
```{r}

# Split the data into train and test sets
train_data <- xts_obj[1:floor(length(xts_obj)*0.8)]
test_data <- xts_obj[(floor(length(xts_obj)*0.8) + 1):length(xts_obj)]

model <- arima(train_data, order = c(best_pdq[1, "p"], best_pdq[1, "d"], best_pdq[1, "q"]))

# Use the model to make predictions on the test data
predictions <- forecast(model, h = length(test_data))


# Plot the predictions against the actual values
dfactvspred <- data.frame(Date = index(test_data), Actual = coredata(test_data), predictions = as.numeric(predictions$fitted))


# Plot the actual values and predictions
plot(test_data, main = "Actual vs Predictions", ylab = "Value")
lines(dfactvspred$predictions, col = "red")
legend("topleft", legend = c("Actual", "Predictions"), col = c("black", "red"), lty = 1)


```




```{r}
rmse <- sqrt(mean((as.numeric(predictions$fitted) - as.numeric(test_data$Return))^2))
print(paste("RMSE: ", rmse))

```
# Conclusion
We explored the steps involved in time series forecasting using the Autoregressive Integrated Moving Average (ARIMA) model. We started with data visualization to gain insights into the time series data. Then, we conducted stationarity tests to determine the stationarity of the series.Than we performed parameter tuning by searching for the optimal values of p, d, and q using a grid search approach. We selected the best combination of parameters based on the AIC value, which measures the model's goodness of fit while penalizing complexity. After obtaining the best parameter values, we split the data into training and test sets and built an ARIMA model using the training data. We used the model to make predictions on the test data. Additionally, we calculated the root mean squared error (RMSE) to evaluate the performance of the model.
# References
